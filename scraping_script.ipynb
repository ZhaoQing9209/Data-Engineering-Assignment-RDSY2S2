{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkbsPxf7ubwrZ59havEbUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brynlai/Data-Engineering-Assignment-RDSY2S2/blob/main/scraping_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6LL91UVlZ1F",
        "outputId": "a6d321a9-7799-4670-b22a-6a66cff0beb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Class to hold scraped data\n",
        "class ScrapedData:\n",
        "  def __init__(self, aid, title, date, publisher, views, comments_count, content):\n",
        "    self.aid = aid\n",
        "    self.title = title\n",
        "    self.date = date\n",
        "    self.publisher = publisher\n",
        "    self.views = views\n",
        "    self.comments_count = comments_count\n",
        "    self.content = content\n",
        "\n",
        "  # String representation of the object\n",
        "  def __str__(self):\n",
        "      return f\"\"\"\n",
        "      Aid: {self.aid}\n",
        "      Title: {self.title}\n",
        "      Date: {self.date}\n",
        "      Publisher: {self.publisher}\n",
        "      Views: {self.views}\n",
        "      Comments Count: {self.comments_count}\n",
        "      Content:\n",
        "      {self.content}\n",
        "        \"\"\"\n",
        "\n",
        "# Scrape article from URL and aid\n",
        "def scrape_article(url, aid):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract title\n",
        "    title = soup.find('title').text\n",
        "\n",
        "    # Extract date\n",
        "    date_tag = soup.find('p', class_='xg1')\n",
        "    date = date_tag.text.split('|')[0].strip() if date_tag else \"Unknown\"\n",
        "\n",
        "    # Extract publisher\n",
        "    publisher_tag = date_tag.find('a') if date_tag else None\n",
        "    publisher = publisher_tag.text if publisher_tag else \"Unknown\"\n",
        "\n",
        "    # Extract views\n",
        "    views_tag = soup.find('em', id='_viewnum')\n",
        "    views = views_tag.text if views_tag else \"0\"\n",
        "\n",
        "    # Extract comments count\n",
        "    comments_tag = soup.find('em', id='_commentnum')\n",
        "    comments_count = comments_tag.text if comments_tag else \"0\"\n",
        "\n",
        "    # Extract content\n",
        "    content_tag = soup.find('td', id='article_content')\n",
        "    content = content_tag.get_text(strip=True) if content_tag else \"\"\n",
        "\n",
        "    return ScrapedData(aid, title, date, publisher, views, comments_count, content)\n",
        "\n",
        "# Main function to orchestrate scraping process\n",
        "def main():\n",
        "    base_url = \"https://b.cari.com.my/portal.php?mod=view&aid=\"\n",
        "\n",
        "    # List of aids to scrape\n",
        "    aid_values = list(range(1,6))  # Should be until 25000+\n",
        "    aid_values.append(20000) # Because AID is sequential.\n",
        "\n",
        "    for aid in aid_values:\n",
        "        url = f\"{base_url}{aid}\"   # Construct full URL\n",
        "\n",
        "        try:\n",
        "            scraped_data = scrape_article(url, aid)   # Scrape data\n",
        "\n",
        "            print(scraped_data)                         # Print data\n",
        "\n",
        "            print(\"\\n------------------------\\n\")       # Print separator\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {url}: {e}\")       # Handle exceptions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()                                           # Run main function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey9AAyeGlkPE",
        "outputId": "39c54246-4691-4006-9af0-69bc826830d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "knahOxSdlmin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}